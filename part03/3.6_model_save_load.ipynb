{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[구글 코랩(Colab)에서 실행하기](https://colab.research.google.com/github/lovedlim/tensorflow/blob/main/Part%203/3.6_model_save_load.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  (60000, 28, 28) (60000,)\n",
      "test  set:  (10000, 28, 28) (10000,)\n",
      "x_train[0, 10:15, 10:15] = array([[0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ],\n",
      "       [0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314],\n",
      "       [0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ],\n",
      "       [0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294],\n",
      "       [0.        , 0.        , 0.        , 0.31764706, 0.94117647]])\n",
      "x_test[0, 10:15, 10:15] = array([[0.        , 0.06666667, 0.25882353, 0.05490196, 0.2627451 ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 파일 경로 설정 (환경에 맞게 수정하세요)\n",
    "mnist_path = '../dataset/mnist/mnist.npz'  # 윈도우 예시\n",
    "#mnist_path = 'D:/datasets/mnist.npz'  # 윈도우 예시\n",
    "# mnist_path = '/home/user/datasets/mnist.npz'  # 리눅스 예시\n",
    "\n",
    "# npz 파일 직접 로드\n",
    "with np.load(mnist_path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "# 데이터 확인\n",
    "print('train set: ', x_train.shape, y_train.shape)\n",
    "print('test  set: ', x_test.shape, y_test.shape)\n",
    "\n",
    "# 정규화\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "print(\"x_train[0, 10:15, 10:15] = \" + repr(x_train[0, 10:15, 10:15]))\n",
    "print(\"x_test[0, 10:15, 10:15] = \" + repr(x_test[0, 10:15, 10:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2287 - accuracy: 0.9322 - val_loss: 0.1183 - val_accuracy: 0.9624\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0925 - accuracy: 0.9711 - val_loss: 0.0921 - val_accuracy: 0.9696\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0665 - accuracy: 0.9796 - val_loss: 0.0905 - val_accuracy: 0.9712\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0489 - accuracy: 0.9852 - val_loss: 0.0961 - val_accuracy: 0.9733\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.0709 - val_accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 0.0842 - val_accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.1023 - val_accuracy: 0.9744\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.0832 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.1119 - val_accuracy: 0.9716\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.1005 - val_accuracy: 0.9763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1dd034745b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드는 10개가 되어야 한다.\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            validation_data=(x_test, y_test), \n",
    "            epochs=10, \n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1. 모델을 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 모델을 h5 포맷으로 저장\n",
    "model.save(\"h5-model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2. 저장된 모델을 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 219818 (858.66 KB)\n",
      "Trainable params: 219818 (858.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 복원\n",
    "h5_model = tf.keras.models.load_model('h5-model.h5')\n",
    "h5_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5 model] loss: 0.10053, acc: 0.97630\n"
     ]
    }
   ],
   "source": [
    "# 모델 검증\n",
    "loss, acc = h5_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'h5 model] loss: {loss:.5f}, acc: {acc:.5f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SavedModel 포맷으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved-model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved-model\\assets\n"
     ]
    }
   ],
   "source": [
    "# 모델을 SavedModel 포맷으로 저장\n",
    "model.save('saved-model')\n",
    "# model.export('saved-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 219818 (858.66 KB)\n",
      "Trainable params: 219818 (858.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 복원\n",
    "saved_model = tf.keras.models.load_model('saved-model')\n",
    "saved_model.summary()\n",
    "\n",
    "# from keras.layers import TFSMLayer\n",
    "\n",
    "# saved_model_path = \"saved-model\"\n",
    "# layer = TFSMLayer(saved_model_path, call_endpoint=\"serving_default\")\n",
    "# saved_model = tf.keras.Sequential([layer])\n",
    "# saved_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5 model] loss: 0.10053, acc: 0.97630\n",
      "saved_model] loss: 0.10053, acc: 0.97630\n"
     ]
    }
   ],
   "source": [
    "# 모델 검증 (HDF5 포맷)\n",
    "loss, acc = h5_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'h5 model] loss: {loss:.5f}, acc: {acc:.5f}')\n",
    "\n",
    "# compile 호출 (필수!)\n",
    "saved_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 모델 검증 (SavedModel 포맷)\n",
    "loss, acc = saved_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'saved_model] loss: {loss:.5f}, acc: {acc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
