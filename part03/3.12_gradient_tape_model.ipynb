{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[구글 코랩(Colab)에서 실행하기](https://colab.research.google.com/github/lovedlim/tensorflow/blob/main/Part%203/3.12_gradient_tape_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load_data()로 데이터셋을 로드 합니다.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 데이터 정규화\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  (60000, 28, 28) (60000,)\n",
      "test  set:  (10000, 28, 28) (10000,)\n",
      "x_train[0, 10:15, 10:15] = array([[0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ],\n",
      "       [0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314],\n",
      "       [0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ],\n",
      "       [0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294],\n",
      "       [0.        , 0.        , 0.        , 0.31764706, 0.94117647]])\n",
      "x_test[0, 10:15, 10:15] = array([[0.        , 0.06666667, 0.25882353, 0.05490196, 0.2627451 ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 파일 경로 설정 (환경에 맞게 수정하세요)\n",
    "mnist_path = '../dataset/mnist/mnist.npz'  # 윈도우 예시\n",
    "#mnist_path = 'D:/datasets/mnist.npz'  # 윈도우 예시\n",
    "# mnist_path = '/home/user/datasets/mnist.npz'  # 리눅스 예시\n",
    "\n",
    "# npz 파일 직접 로드\n",
    "with np.load(mnist_path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "# 데이터 확인\n",
    "print('train set: ', x_train.shape, y_train.shape)\n",
    "print('test  set: ', x_test.shape, y_test.shape)\n",
    "\n",
    "# 정규화\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "print(\"x_train[0, 10:15, 10:15] = \" + repr(x_train[0, 10:15, 10:15]))\n",
    "print(\"x_test[0, 10:15, 10:15] = \" + repr(x_test[0, 10:15, 10:15]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-3-3. GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), \n",
    "])\n",
    "\n",
    "# 손실함수 정의\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기록을 위한 Metric 정의\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 생성 함수\n",
    "def get_batches(x, y, batch_size=32):\n",
    "    for i in range(int(x.shape[0] // batch_size)):\n",
    "        x_batch = x[i * batch_size: (i + 1) * batch_size]\n",
    "        y_batch = y[i * batch_size: (i + 1) * batch_size]\n",
    "        yield (np.asarray(x_batch), np.asarray(y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    # GradientTape 적용\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 예측\n",
    "        prediction = model(images, training=True)\n",
    "        # 손실\n",
    "        loss = loss_function(labels, prediction)\n",
    "    # 미분 (gradient) 값 계산\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimizer 적용\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # loss, accuracy 계산\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, prediction)\n",
    "\n",
    "@tf.function\n",
    "def valid_step(images, labels):\n",
    "    # 예측\n",
    "    prediction = model(images, training=False)    \n",
    "    # 손실\n",
    "    loss = loss_function(labels, prediction)\n",
    "\n",
    "    # loss, accuracy 계산\n",
    "    valid_loss(loss)\n",
    "    valid_accuracy(labels, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.2365, acc: 92.97%, val_loss: 0.1311, val_acc: 95.94%\n",
      "epoch: 2, loss: 0.1670, acc: 94.99%, val_loss: 0.1201, val_acc: 96.21%\n",
      "epoch: 3, loss: 0.1326, acc: 96.02%, val_loss: 0.1148, val_acc: 96.42%\n",
      "epoch: 4, loss: 0.1118, acc: 96.64%, val_loss: 0.1183, val_acc: 96.42%\n",
      "epoch: 5, loss: 0.0969, acc: 97.07%, val_loss: 0.1190, val_acc: 96.48%\n"
     ]
    }
   ],
   "source": [
    "# 초기화 코드\n",
    "#train_loss.reset_states()\n",
    "#train_accuracy.reset_states()\n",
    "#valid_loss.reset_states()\n",
    "#valid_accuracy.reset_states()\n",
    "train_loss.reset_state()\n",
    "train_accuracy.reset_state()\n",
    "valid_loss.reset_state()\n",
    "valid_accuracy.reset_state()\n",
    "\n",
    "# Epoch 반복\n",
    "for epoch in range(5):\n",
    "    # batch 별 순회\n",
    "    for images, labels in get_batches(x_train, y_train):\n",
    "        # train_step\n",
    "        train_step(images, labels)    \n",
    "\n",
    "    for images, labels in get_batches(x_test, y_test):\n",
    "        # valid_step\n",
    "        valid_step(images, labels)\n",
    "\n",
    "    # 결과 출력\n",
    "    metric_template = 'epoch: {}, loss: {:.4f}, acc: {:.2f}%, val_loss: {:.4f}, val_acc: {:.2f}%'\n",
    "    print(metric_template.format(epoch+1, train_loss.result(), train_accuracy.result()*100, \n",
    "                                 valid_loss.result(), valid_accuracy.result()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
