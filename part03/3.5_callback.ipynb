{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[구글 코랩(Colab)에서 실행하기](https://colab.research.google.com/github/lovedlim/tensorflow/blob/main/Part%203/3.5_callback.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport tensorflow as tf\\n\\n# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\\nmnist = tf.keras.datasets.mnist\\n\\n# load_data()로 데이터셋을 로드 합니다.\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\\n# 로드된 데이터셋 확인\\nprint('train set: ', x_train.shape, y_train.shape)\\nprint('test  set: ', x_test.shape, y_test.shape)\\n\\n# 데이터 정규화\\nx_train = x_train / x_train.max() # max: 255\\nx_test = x_test / x_test.max() # max: 255\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load_data()로 데이터셋을 로드 합니다.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 로드된 데이터셋 확인\n",
    "print('train set: ', x_train.shape, y_train.shape)\n",
    "print('test  set: ', x_test.shape, y_test.shape)\n",
    "\n",
    "# 데이터 정규화\n",
    "x_train = x_train / x_train.max() # max: 255\n",
    "x_test = x_test / x_test.max() # max: 255\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  (60000, 28, 28) (60000,)\n",
      "test  set:  (10000, 28, 28) (10000,)\n",
      "x_train[0, 10:15, 10:15] = array([[0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ],\n",
      "       [0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314],\n",
      "       [0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ],\n",
      "       [0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294],\n",
      "       [0.        , 0.        , 0.        , 0.31764706, 0.94117647]])\n",
      "x_test[0, 10:15, 10:15] = array([[0.        , 0.06666667, 0.25882353, 0.05490196, 0.2627451 ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 파일 경로 설정 (환경에 맞게 수정하세요)\n",
    "mnist_path = '../dataset/mnist/mnist.npz'  # 윈도우 예시\n",
    "#mnist_path = 'D:/datasets/mnist.npz'  # 윈도우 예시\n",
    "# mnist_path = '/home/user/datasets/mnist.npz'  # 리눅스 예시\n",
    "\n",
    "# npz 파일 직접 로드\n",
    "with np.load(mnist_path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "# 데이터 확인\n",
    "print('train set: ', x_train.shape, y_train.shape)\n",
    "print('test  set: ', x_test.shape, y_test.shape)\n",
    "\n",
    "# 정규화\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "print(\"x_train[0, 10:15, 10:15] = \" + repr(x_train[0, 10:15, 10:15]))\n",
    "print(\"x_test[0, 10:15, 10:15] = \" + repr(x_test[0, 10:15, 10:15]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. 모델 체크포인트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 설정\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(#filepath='tmp_checkpoint.ckpt', \n",
    "                                                filepath='tmp_checkpoint.weights.h5',  # 확장자 수정\n",
    "                                                save_weights_only=True, \n",
    "                                                save_best_only=True, \n",
    "                                                monitor='val_loss', \n",
    "                                                verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1864/1875 [============================>.] - ETA: 0s - loss: 0.2276 - accuracy: 0.9329\n",
      "Epoch 1: val_loss improved from inf to 0.11703, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2270 - accuracy: 0.9331 - val_loss: 0.1170 - val_accuracy: 0.9642\n",
      "Epoch 2/10\n",
      "1850/1875 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9713\n",
      "Epoch 2: val_loss improved from 0.11703 to 0.10187, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0932 - accuracy: 0.9712 - val_loss: 0.1019 - val_accuracy: 0.9679\n",
      "Epoch 3/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9794\n",
      "Epoch 3: val_loss improved from 0.10187 to 0.09097, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0656 - accuracy: 0.9794 - val_loss: 0.0910 - val_accuracy: 0.9719\n",
      "Epoch 4/10\n",
      "1855/1875 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9839\n",
      "Epoch 4: val_loss did not improve from 0.09097\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.0917 - val_accuracy: 0.9733\n",
      "Epoch 5/10\n",
      "1852/1875 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9872\n",
      "Epoch 5: val_loss improved from 0.09097 to 0.08280, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0382 - accuracy: 0.9872 - val_loss: 0.0828 - val_accuracy: 0.9782\n",
      "Epoch 6/10\n",
      "1857/1875 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9896\n",
      "Epoch 6: val_loss improved from 0.08280 to 0.08033, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.0803 - val_accuracy: 0.9780\n",
      "Epoch 7/10\n",
      "1853/1875 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9905\n",
      "Epoch 7: val_loss improved from 0.08033 to 0.07539, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.0754 - val_accuracy: 0.9809\n",
      "Epoch 8/10\n",
      "1855/1875 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9923\n",
      "Epoch 8: val_loss did not improve from 0.07539\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0847 - val_accuracy: 0.9797\n",
      "Epoch 9/10\n",
      "1861/1875 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9927\n",
      "Epoch 9: val_loss did not improve from 0.07539\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.0825 - val_accuracy: 0.9776\n",
      "Epoch 10/10\n",
      "1856/1875 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 10: val_loss did not improve from 0.07539\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0881 - val_accuracy: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1adae171330>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test), \n",
    "          epochs=10, \n",
    "          callbacks=[checkpoint]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 937us/step - loss: 0.0881 - accuracy: 0.9789\n",
      "체크포인트 로드 전: loss: 0.0881, acc: 0.9789\n",
      "313/313 [==============================] - 0s 965us/step - loss: 0.0754 - accuracy: 0.9809\n",
      "체크포인트 로드 후: loss: 0.0754, acc: 0.9809\n"
     ]
    }
   ],
   "source": [
    "# 모델 체크포인트 로드 전\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f'체크포인트 로드 전: loss: {loss:.4f}, acc: {acc:.4f}')\n",
    "\n",
    "# 체크포인트 파일을 모델에 로드\n",
    "#model.load_weights('tmp_checkpoint.ckpt')\n",
    "model.load_weights('tmp_checkpoint.weights.h5')\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f'체크포인트 로드 후: loss: {loss:.4f}, acc: {acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. 조기종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 콜백 생성\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2357 - accuracy: 0.9299 - val_loss: 0.1186 - val_accuracy: 0.9641\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0957 - accuracy: 0.9711 - val_loss: 0.0895 - val_accuracy: 0.9719\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0663 - accuracy: 0.9791 - val_loss: 0.0768 - val_accuracy: 0.9761\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0751 - val_accuracy: 0.9775\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 0.0894 - val_accuracy: 0.9769\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0788 - val_accuracy: 0.9773\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 0.0772 - val_accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1adca7a6230>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test), \n",
    "          epochs=20, \n",
    "          callbacks=[earlystopping]\n",
    "          )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3. 학습률 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def scheduler(epoch, lr):\n",
    "    tf.print(f'learning_rate: {lr:.5f}')\n",
    "    # 첫 5 에포크 동안 유지\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "    # 학습률 감소 적용\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "'''\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    print(f'learning_rate: {lr:.5f}')  # tf.print → print 로 변경\n",
    "    if epoch < 5:\n",
    "        return float(lr)  # 명시적으로 float 반환\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))  # float으로 변환\n",
    "\n",
    "# 콜백 객체생성 및 scheduler 함수 적용\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "model.compile(tf.keras.optimizers.SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# 초기 학습률 확인(0.01)\n",
    "#print(round(model.optimizer.lr.numpy(), 5))\n",
    "print(round(model.optimizer.learning_rate.numpy(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.01000\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6631 - accuracy: 0.8171 - val_loss: 0.2921 - val_accuracy: 0.9155 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2612 - accuracy: 0.9254 - val_loss: 0.2226 - val_accuracy: 0.9359 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1999 - accuracy: 0.9418 - val_loss: 0.1784 - val_accuracy: 0.9474 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1638 - accuracy: 0.9521 - val_loss: 0.1527 - val_accuracy: 0.9543 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1386 - accuracy: 0.9597 - val_loss: 0.1396 - val_accuracy: 0.9580 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1190 - accuracy: 0.9647 - val_loss: 0.1202 - val_accuracy: 0.9629 - lr: 0.0090\n",
      "learning_rate: 0.00905\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1047 - accuracy: 0.9696 - val_loss: 0.1120 - val_accuracy: 0.9662 - lr: 0.0082\n",
      "learning_rate: 0.00819\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0936 - accuracy: 0.9725 - val_loss: 0.1062 - val_accuracy: 0.9672 - lr: 0.0074\n",
      "learning_rate: 0.00741\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0855 - accuracy: 0.9747 - val_loss: 0.0996 - val_accuracy: 0.9695 - lr: 0.0067\n",
      "learning_rate: 0.00670\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0782 - accuracy: 0.9774 - val_loss: 0.0947 - val_accuracy: 0.9706 - lr: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00607"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test), \n",
    "          epochs=10,\n",
    "          # 학습률 스케줄러 적용\n",
    "          callbacks=[lr_scheduler]\n",
    "          )\n",
    "# 최종 학습률 스케줄러 확인\n",
    "#round(model.optimizer.lr.numpy(), 5)\n",
    "round(model.optimizer.learning_rate.numpy(), 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-4. 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2319 - accuracy: 0.9311 - val_loss: 0.1162 - val_accuracy: 0.9645\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0924 - accuracy: 0.9719 - val_loss: 0.0900 - val_accuracy: 0.9698\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0640 - accuracy: 0.9798 - val_loss: 0.0909 - val_accuracy: 0.9721\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0492 - accuracy: 0.9845 - val_loss: 0.0877 - val_accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.0822 - val_accuracy: 0.9777\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 0.0711 - val_accuracy: 0.9789\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.0818 - val_accuracy: 0.9773\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0840 - val_accuracy: 0.9800\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.1045 - val_accuracy: 0.9764\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.0853 - val_accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1adae4b1000>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서보드 저장 경로 지정\n",
    "log_dir = 'tensorboard'\n",
    "\n",
    "# 텐서보드 콜백 정의\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            validation_data=(x_test, y_test), \n",
    "            epochs=10, \n",
    "            callbacks=[tensorboard],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드 extension 로드\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-84c52e11cf10e949\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-84c52e11cf10e949\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 텐서보드 출력 매직 커멘드\n",
    "%tensorboard --logdir {log_dir}\n",
    "#%tensorboard --logdir=log_dir\n",
    "#%tensorboard --logdir=your_log_dir\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
