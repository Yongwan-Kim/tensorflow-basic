{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[구글 코랩(Colab)에서 실행하기](https://colab.research.google.com/github/lovedlim/tensorflow/blob/main/Part%203/3.5_callback.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport tensorflow as tf\\n\\n# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\\nmnist = tf.keras.datasets.mnist\\n\\n# load_data()로 데이터셋을 로드 합니다.\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\\n# 로드된 데이터셋 확인\\nprint('train set: ', x_train.shape, y_train.shape)\\nprint('test  set: ', x_test.shape, y_test.shape)\\n\\n# 데이터 정규화\\nx_train = x_train / x_train.max() # max: 255\\nx_test = x_test / x_test.max() # max: 255\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load_data()로 데이터셋을 로드 합니다.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 로드된 데이터셋 확인\n",
    "print('train set: ', x_train.shape, y_train.shape)\n",
    "print('test  set: ', x_test.shape, y_test.shape)\n",
    "\n",
    "# 데이터 정규화\n",
    "x_train = x_train / x_train.max() # max: 255\n",
    "x_test = x_test / x_test.max() # max: 255\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  (60000, 28, 28) (60000,)\n",
      "test  set:  (10000, 28, 28) (10000,)\n",
      "x_train[0, 10:15, 10:15] = array([[0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ],\n",
      "       [0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314],\n",
      "       [0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ],\n",
      "       [0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294],\n",
      "       [0.        , 0.        , 0.        , 0.31764706, 0.94117647]])\n",
      "x_test[0, 10:15, 10:15] = array([[0.        , 0.06666667, 0.25882353, 0.05490196, 0.2627451 ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 파일 경로 설정 (환경에 맞게 수정하세요)\n",
    "mnist_path = '../dataset/mnist/mnist.npz'  # 윈도우 예시\n",
    "#mnist_path = 'D:/datasets/mnist.npz'  # 윈도우 예시\n",
    "# mnist_path = '/home/user/datasets/mnist.npz'  # 리눅스 예시\n",
    "\n",
    "# npz 파일 직접 로드\n",
    "with np.load(mnist_path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "# 데이터 확인\n",
    "print('train set: ', x_train.shape, y_train.shape)\n",
    "print('test  set: ', x_test.shape, y_test.shape)\n",
    "\n",
    "# 정규화\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "print(\"x_train[0, 10:15, 10:15] = \" + repr(x_train[0, 10:15, 10:15]))\n",
    "print(\"x_test[0, 10:15, 10:15] = \" + repr(x_test[0, 10:15, 10:15]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. 모델 체크포인트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 설정\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(#filepath='tmp_checkpoint.ckpt', \n",
    "                                                filepath='tmp_checkpoint.weights.h5',  # 확장자 수정\n",
    "                                                save_weights_only=True, \n",
    "                                                save_best_only=True, \n",
    "                                                monitor='val_loss', \n",
    "                                                verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1864/1875 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9320\n",
      "Epoch 1: val_loss improved from inf to 0.11391, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2241 - accuracy: 0.9322 - val_loss: 0.1139 - val_accuracy: 0.9643\n",
      "Epoch 2/10\n",
      "1852/1875 [============================>.] - ETA: 0s - loss: 0.0954 - accuracy: 0.9705\n",
      "Epoch 2: val_loss improved from 0.11391 to 0.08453, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0957 - accuracy: 0.9704 - val_loss: 0.0845 - val_accuracy: 0.9742\n",
      "Epoch 3/10\n",
      "1868/1875 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.9790\n",
      "Epoch 3: val_loss improved from 0.08453 to 0.08190, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0670 - accuracy: 0.9790 - val_loss: 0.0819 - val_accuracy: 0.9752\n",
      "Epoch 4/10\n",
      "1862/1875 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9843\n",
      "Epoch 4: val_loss did not improve from 0.08190\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 0.0909 - val_accuracy: 0.9738\n",
      "Epoch 5/10\n",
      "1862/1875 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9877\n",
      "Epoch 5: val_loss did not improve from 0.08190\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 0.0946 - val_accuracy: 0.9718\n",
      "Epoch 6/10\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9886\n",
      "Epoch 6: val_loss improved from 0.08190 to 0.07840, saving model to tmp_checkpoint.weights.h5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.0784 - val_accuracy: 0.9790\n",
      "Epoch 7/10\n",
      "1868/1875 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9908\n",
      "Epoch 7: val_loss did not improve from 0.07840\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0839 - val_accuracy: 0.9782\n",
      "Epoch 8/10\n",
      "1862/1875 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9923\n",
      "Epoch 8: val_loss did not improve from 0.07840\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0906 - val_accuracy: 0.9771\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9925\n",
      "Epoch 9: val_loss did not improve from 0.07840\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0934 - val_accuracy: 0.9770\n",
      "Epoch 10/10\n",
      "1851/1875 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9939\n",
      "Epoch 10: val_loss did not improve from 0.07840\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.1061 - val_accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20022d14b20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test), \n",
    "          epochs=10, \n",
    "          callbacks=[checkpoint]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9790\n",
      "체크포인트 로드 전: loss: 0.1061, acc: 0.9790\n",
      "313/313 [==============================] - 0s 981us/step - loss: 0.0784 - accuracy: 0.9790\n",
      "체크포인트 로드 후: loss: 0.0784, acc: 0.9790\n"
     ]
    }
   ],
   "source": [
    "# 모델 체크포인트 로드 전\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f'체크포인트 로드 전: loss: {loss:.4f}, acc: {acc:.4f}')\n",
    "\n",
    "# 체크포인트 파일을 모델에 로드\n",
    "#model.load_weights('tmp_checkpoint.ckpt')\n",
    "model.load_weights('tmp_checkpoint.weights.h5')\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f'체크포인트 로드 후: loss: {loss:.4f}, acc: {acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. 조기종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 콜백 생성\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2347 - accuracy: 0.9305 - val_loss: 0.1104 - val_accuracy: 0.9647\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0937 - accuracy: 0.9717 - val_loss: 0.0829 - val_accuracy: 0.9750\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0646 - accuracy: 0.9796 - val_loss: 0.0838 - val_accuracy: 0.9750\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0499 - accuracy: 0.9841 - val_loss: 0.0850 - val_accuracy: 0.9743\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.0912 - val_accuracy: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2004168de40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test), \n",
    "          epochs=20, \n",
    "          callbacks=[earlystopping]\n",
    "          )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3. 학습률 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def scheduler(epoch, lr):\n",
    "    tf.print(f'learning_rate: {lr:.5f}')\n",
    "    # 첫 5 에포크 동안 유지\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "    # 학습률 감소 적용\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "'''\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    print(f'learning_rate: {lr:.5f}')  # tf.print → print 로 변경\n",
    "    if epoch < 5:\n",
    "        return float(lr)  # 명시적으로 float 반환\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))  # float으로 변환\n",
    "\n",
    "# 콜백 객체생성 및 scheduler 함수 적용\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "model.compile(tf.keras.optimizers.SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# 초기 학습률 확인(0.01)\n",
    "#print(round(model.optimizer.lr.numpy(), 5))\n",
    "print(round(model.optimizer.learning_rate.numpy(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.01000\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6269 - accuracy: 0.8313 - val_loss: 0.2798 - val_accuracy: 0.9198 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2499 - accuracy: 0.9286 - val_loss: 0.2082 - val_accuracy: 0.9398 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.9448 - val_loss: 0.1693 - val_accuracy: 0.9502 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1575 - accuracy: 0.9548 - val_loss: 0.1462 - val_accuracy: 0.9560 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1326 - accuracy: 0.9617 - val_loss: 0.1322 - val_accuracy: 0.9599 - lr: 0.0100\n",
      "learning_rate: 0.01000\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1134 - accuracy: 0.9672 - val_loss: 0.1130 - val_accuracy: 0.9652 - lr: 0.0090\n",
      "learning_rate: 0.00905\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0994 - accuracy: 0.9710 - val_loss: 0.1063 - val_accuracy: 0.9669 - lr: 0.0082\n",
      "learning_rate: 0.00819\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0882 - accuracy: 0.9750 - val_loss: 0.1007 - val_accuracy: 0.9708 - lr: 0.0074\n",
      "learning_rate: 0.00741\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0799 - accuracy: 0.9769 - val_loss: 0.0925 - val_accuracy: 0.9722 - lr: 0.0067\n",
      "learning_rate: 0.00670\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0731 - accuracy: 0.9790 - val_loss: 0.0904 - val_accuracy: 0.9729 - lr: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00607"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test), \n",
    "          epochs=10,\n",
    "          # 학습률 스케줄러 적용\n",
    "          callbacks=[lr_scheduler]\n",
    "          )\n",
    "# 최종 학습률 스케줄러 확인\n",
    "#round(model.optimizer.lr.numpy(), 5)\n",
    "round(model.optimizer.learning_rate.numpy(), 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-4. 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2290 - accuracy: 0.9311 - val_loss: 0.1194 - val_accuracy: 0.9619\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0948 - accuracy: 0.9711 - val_loss: 0.0833 - val_accuracy: 0.9743\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0641 - accuracy: 0.9799 - val_loss: 0.0749 - val_accuracy: 0.9767\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.0727 - val_accuracy: 0.9781\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.0893 - val_accuracy: 0.9753\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 0.0800 - val_accuracy: 0.9788\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.0816 - val_accuracy: 0.9777\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.0847 - val_accuracy: 0.9779\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.0962 - val_accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.1134 - val_accuracy: 0.9726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2004129de70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서보드 저장 경로 지정\n",
    "log_dir = 'tensorboard'\n",
    "\n",
    "# 텐서보드 콜백 정의\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            validation_data=(x_test, y_test), \n",
    "            epochs=10, \n",
    "            callbacks=[tensorboard],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드 extension 로드\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8e51cb01671a3652\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8e51cb01671a3652\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 텐서보드 출력 매직 커멘드\n",
    "%tensorboard --logdir {log_dir}\n",
    "#%tensorboard --logdir=log_dir\n",
    "#%tensorboard --logdir=your_log_dir\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
