{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[구글 코랩(Colab)에서 실행하기](https://colab.research.google.com/github/lovedlim/tensorflow/blob/main/Part%203/3.5_callback.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport tensorflow as tf\\n\\n# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\\nmnist = tf.keras.datasets.mnist\\n\\n# load_data()로 데이터셋을 로드 합니다.\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\\n# 로드된 데이터셋 확인\\nprint('train set: ', x_train.shape, y_train.shape)\\nprint('test  set: ', x_test.shape, y_test.shape)\\n\\n# 데이터 정규화\\nx_train = x_train / x_train.max() # max: 255\\nx_test = x_test / x_test.max() # max: 255\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load_data()로 데이터셋을 로드 합니다.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 로드된 데이터셋 확인\n",
    "print('train set: ', x_train.shape, y_train.shape)\n",
    "print('test  set: ', x_test.shape, y_test.shape)\n",
    "\n",
    "# 데이터 정규화\n",
    "x_train = x_train / x_train.max() # max: 255\n",
    "x_test = x_test / x_test.max() # max: 255\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  (60000, 28, 28) (60000,)\n",
      "test  set:  (10000, 28, 28) (10000,)\n",
      "x_train[0, 10:15, 10:15] = array([[0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ],\n",
      "       [0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314],\n",
      "       [0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ],\n",
      "       [0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294],\n",
      "       [0.        , 0.        , 0.        , 0.31764706, 0.94117647]])\n",
      "x_test[0, 10:15, 10:15] = array([[0.        , 0.06666667, 0.25882353, 0.05490196, 0.2627451 ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 파일 경로 설정 (환경에 맞게 수정하세요)\n",
    "mnist_path = '../dataset/mnist/mnist.npz'  # 윈도우 예시\n",
    "#mnist_path = 'D:/datasets/mnist.npz'  # 윈도우 예시\n",
    "# mnist_path = '/home/user/datasets/mnist.npz'  # 리눅스 예시\n",
    "\n",
    "# npz 파일 직접 로드\n",
    "with np.load(mnist_path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "# 데이터 확인\n",
    "print('train set: ', x_train.shape, y_train.shape)\n",
    "print('test  set: ', x_test.shape, y_test.shape)\n",
    "\n",
    "# 정규화\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "print(\"x_train[0, 10:15, 10:15] = \" + repr(x_train[0, 10:15, 10:15]))\n",
    "print(\"x_test[0, 10:15, 10:15] = \" + repr(x_test[0, 10:15, 10:15]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. 모델 체크포인트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 설정\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(#filepath='tmp_checkpoint.ckpt', \n",
    "                                                filepath='tmp_checkpoint.weights.h5',  # 확장자 수정\n",
    "                                                save_weights_only=True, \n",
    "                                                save_best_only=True, \n",
    "                                                monitor='val_loss', \n",
    "                                                verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1857/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.4147\n",
      "Epoch 1: val_loss improved from None to 0.12931, saving model to tmp_checkpoint.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9337 - loss: 0.2249 - val_accuracy: 0.9606 - val_loss: 0.1293\n",
      "Epoch 2/10\n",
      "\u001b[1m1860/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.0977\n",
      "Epoch 2: val_loss improved from 0.12931 to 0.10151, saving model to tmp_checkpoint.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0939 - val_accuracy: 0.9682 - val_loss: 0.1015\n",
      "Epoch 3/10\n",
      "\u001b[1m1856/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9800 - loss: 0.0640\n",
      "Epoch 3: val_loss improved from 0.10151 to 0.08506, saving model to tmp_checkpoint.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0676 - val_accuracy: 0.9734 - val_loss: 0.0851\n",
      "Epoch 4/10\n",
      "\u001b[1m1857/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9854 - loss: 0.0466\n",
      "Epoch 4: val_loss did not improve from 0.08506\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0493 - val_accuracy: 0.9737 - val_loss: 0.0948\n",
      "Epoch 5/10\n",
      "\u001b[1m1841/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0375\n",
      "Epoch 5: val_loss improved from 0.08506 to 0.07174, saving model to tmp_checkpoint.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0399 - val_accuracy: 0.9802 - val_loss: 0.0717\n",
      "Epoch 6/10\n",
      "\u001b[1m1869/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0263\n",
      "Epoch 6: val_loss did not improve from 0.07174\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0322 - val_accuracy: 0.9806 - val_loss: 0.0781\n",
      "Epoch 7/10\n",
      "\u001b[1m1873/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0233\n",
      "Epoch 7: val_loss did not improve from 0.07174\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0275 - val_accuracy: 0.9779 - val_loss: 0.0898\n",
      "Epoch 8/10\n",
      "\u001b[1m1847/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0245\n",
      "Epoch 8: val_loss did not improve from 0.07174\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0262 - val_accuracy: 0.9673 - val_loss: 0.1346\n",
      "Epoch 9/10\n",
      "\u001b[1m1855/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0199\n",
      "Epoch 9: val_loss did not improve from 0.07174\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0222 - val_accuracy: 0.9731 - val_loss: 0.1101\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0179\n",
      "Epoch 10: val_loss did not improve from 0.07174\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0196 - val_accuracy: 0.9776 - val_loss: 0.0985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x280ebea5d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test), \n",
    "          epochs=10, \n",
    "          callbacks=[checkpoint]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.9776 - loss: 0.0985\n",
      "체크포인트 로드 전: loss: 0.0985, acc: 0.9776\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9802 - loss: 0.0717\n",
      "체크포인트 로드 후: loss: 0.0717, acc: 0.9802\n"
     ]
    }
   ],
   "source": [
    "# 모델 체크포인트 로드 전\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f'체크포인트 로드 전: loss: {loss:.4f}, acc: {acc:.4f}')\n",
    "\n",
    "# 체크포인트 파일을 모델에 로드\n",
    "#model.load_weights('tmp_checkpoint.ckpt')\n",
    "model.load_weights('tmp_checkpoint.weights.h5')\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f'체크포인트 로드 후: loss: {loss:.4f}, acc: {acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. 조기종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 콜백 생성\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.2413 - val_accuracy: 0.9662 - val_loss: 0.1101\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0972 - val_accuracy: 0.9714 - val_loss: 0.0949\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0653 - val_accuracy: 0.9770 - val_loss: 0.0773\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0496 - val_accuracy: 0.9789 - val_loss: 0.0724\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0388 - val_accuracy: 0.9717 - val_loss: 0.0903\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0323 - val_accuracy: 0.9755 - val_loss: 0.0874\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0285 - val_accuracy: 0.9791 - val_loss: 0.0745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x280edec7890>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test), \n",
    "          epochs=20, \n",
    "          callbacks=[earlystopping]\n",
    "          )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3. 학습률 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def scheduler(epoch, lr):\n",
    "    tf.print(f'learning_rate: {lr:.5f}')\n",
    "    # 첫 5 에포크 동안 유지\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "    # 학습률 감소 적용\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "'''\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    print(f'learning_rate: {lr:.5f}')  # tf.print → print 로 변경\n",
    "    if epoch < 5:\n",
    "        return float(lr)  # 명시적으로 float 반환\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))  # float으로 변환\n",
    "\n",
    "# 콜백 객체생성 및 scheduler 함수 적용\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "model.compile(tf.keras.optimizers.SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# 초기 학습률 확인(0.01)\n",
    "#print(round(model.optimizer.lr.numpy(), 5))\n",
    "print(round(model.optimizer.learning_rate.numpy(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.00607\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0154 - val_accuracy: 0.9780 - val_loss: 0.0780 - learning_rate: 0.0061\n",
      "learning_rate: 0.00607\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9977 - loss: 0.0144 - val_accuracy: 0.9785 - val_loss: 0.0768 - learning_rate: 0.0061\n",
      "learning_rate: 0.00607\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0134 - val_accuracy: 0.9777 - val_loss: 0.0787 - learning_rate: 0.0061\n",
      "learning_rate: 0.00607\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0127 - val_accuracy: 0.9778 - val_loss: 0.0785 - learning_rate: 0.0061\n",
      "learning_rate: 0.00607\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0119 - val_accuracy: 0.9785 - val_loss: 0.0788 - learning_rate: 0.0061\n",
      "learning_rate: 0.00607\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0110 - val_accuracy: 0.9786 - val_loss: 0.0789 - learning_rate: 0.0055\n",
      "learning_rate: 0.00549\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0104 - val_accuracy: 0.9785 - val_loss: 0.0789 - learning_rate: 0.0050\n",
      "learning_rate: 0.00497\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0098 - val_accuracy: 0.9783 - val_loss: 0.0792 - learning_rate: 0.0045\n",
      "learning_rate: 0.00449\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0092 - val_accuracy: 0.9785 - val_loss: 0.0793 - learning_rate: 0.0041\n",
      "learning_rate: 0.00407\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0088 - val_accuracy: 0.9793 - val_loss: 0.0793 - learning_rate: 0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(0.00368)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test), \n",
    "          epochs=10,\n",
    "          # 학습률 스케줄러 적용\n",
    "          callbacks=[lr_scheduler]\n",
    "          )\n",
    "# 최종 학습률 스케줄러 확인\n",
    "#round(model.optimizer.lr.numpy(), 5)\n",
    "round(model.optimizer.learning_rate.numpy(), 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-4. 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), # 노드 10개로 생성\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2342 - val_accuracy: 0.9648 - val_loss: 0.1203\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0951 - val_accuracy: 0.9692 - val_loss: 0.0966\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0661 - val_accuracy: 0.9734 - val_loss: 0.0830\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0514 - val_accuracy: 0.9762 - val_loss: 0.0756\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0393 - val_accuracy: 0.9730 - val_loss: 0.0948\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0335 - val_accuracy: 0.9730 - val_loss: 0.0955\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0286 - val_accuracy: 0.9790 - val_loss: 0.0731\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0225 - val_accuracy: 0.9789 - val_loss: 0.0851\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0218 - val_accuracy: 0.9826 - val_loss: 0.0748\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0183 - val_accuracy: 0.9725 - val_loss: 0.1237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28101e089e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서보드 저장 경로 지정\n",
    "log_dir = 'tensorboard'\n",
    "\n",
    "# 텐서보드 콜백 정의\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            validation_data=(x_test, y_test), \n",
    "            epochs=10, \n",
    "            callbacks=[tensorboard],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# 텐서보드 extension 로드\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-41737c39d71bf7a4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-41737c39d71bf7a4\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 텐서보드 출력 매직 커멘드\n",
    "#%tensorboard --logdir {log_dir}\n",
    "%tensorboard --logdir=your_log_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
